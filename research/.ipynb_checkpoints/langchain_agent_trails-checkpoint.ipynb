{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f95d4c5f-84fa-4bb5-938b-8de53b1a0370",
   "metadata": {},
   "source": [
    "# Langchain Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf85b66-b883-42bc-874d-2b810a61eb01",
   "metadata": {},
   "source": [
    "## WikiPedia Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9f1f5e-4b08-4584-aeff-799b039d3ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Hunter × Hunter\\nSummary: Hunter × Hunter (pronounced \"hunter hunter\") is a Japanese manga series written and illustrated by Yoshihiro Togashi. It has been serialized in Shueisha\\'s shōnen manga magazine Weekly Shōnen Jump since March 1998, although the manga has frequently gone on extended hiatuses since 2006. Its chapters have been collected in 38 tankōbon volumes as of September 2024. The story focuses on a young boy named Gon Freecss who discovers that his father, who left him at a young age, is actually a world-renowned Hunter, a licensed professional who specializes in fantastical pursuits such as locating rare or unidentified animal species, treasure hunting, surveying unexplored enclaves, or hunting down lawless individuals. Gon departs on a journey to become a Hunter and eventually find his father. Along the way, Gon meets various other Hunters and encounters the paranormal.\\nHunter × Hunter was adapted into a 62-episode anime television series by Nippon Animation and directed by Kazuhiro Furuhashi, which ran on Fuji Television from October 1999 to March 2001. Three separate original video animations (OVAs) totaling 30 episodes were subsequently produced by Nippon Animation and released in Japan from 2002 to 2004. A second anime television series by Madhouse aired on Nippon Television from October 2011 to September 2014, totaling 148 episodes, with two animated theatrical films released in 2013. There are also numerous audio albums, video games, musicals, and other media based on Hunter × Hunter.\\nThe manga has been licensed for English release in North America by Viz Media since April 2005. Both television series have been also licensed by Viz Media, with the first series having aired on the Funimation Channel in 2009 and the second series broadcast on Adult Swim\\'s Toonami programming block from April 2016 to June 2019.\\nHunter × Hunter has been a huge critical and financial success and has become one of the best-selling manga series of all time, having over 84 million copies in circulation by July 2022.\\n\\n\\n\\nPage: List of Hunter × Hunter characters\\nSummary: The Hunter × Hunter manga series, created by Yoshihiro Togashi, features an extensive cast of characters. Such as Shihad Gandhi. It takes place in a fictional universe where licensed specialists known as Hunters travel the world taking on special jobs ranging from treasure hunting to assassination. The story initially focuses on Gon Freecss and his quest to become a Hunter in order to find his father, Ging, who is himself a famous Hunter. On the way, Gon meets and becomes close friends with Killua Zoldyck, Kurapika and Leorio Paradinight.\\nAlthough most characters are human, most possess superhuman strength and/or supernatural abilities due to Nen, the ability to control one\\'s own life energy or aura. The world of the series also includes fantastical beasts such as the Chimera Ants or the Five great calamities.\\n\\nPage: Kraven the Hunter\\nSummary: Kraven the Hunter (Sergei Nikolaevich Kravinoff; Russian: Сергей Николаевич Кравинов) is a supervillain appearing in American comic books published by Marvel Comics. Created by writer Stan Lee and artist Steve Ditko, the character first appeared in The Amazing Spider-Man #15 (August 1964) as an adversary for the superhero Spider-Man. He since endured as one of the web-slinger\\'s most formidable foes, and is part of the collective of adversaries that make up Spider-Man\\'s rogues\\' gallery. Kraven has also come into conflict with other heroes, such as Black Panther and Tigra. He is the half-brother of the Chameleon and is one of the founding members of the Sinister Six.\\nIn Kraven\\'s first appearance, he calls Spider-Man \"the most dangerous game\", a direct reference to the 1924 short story of the same name, in which General Zaroff, a Russian big-game hunter (and a primary inspiration for the character), hunts people for sport.\\nKraven is typically portrayed as a renowned big-game hunter whose goal in life is to beat Spider-Man to pr'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Create Wikipedia Tool\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "wikipedia.run(\"HUNTER X HUNTER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95bb243-435f-45af-a0ac-3adca2839954",
   "metadata": {},
   "source": [
    "## Arxiv Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77d7f58-e064-4d3c-838e-259e2fc4ff1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2016-05-26\\nTitle: Heat-bath random walks with Markov bases\\nAuthors: Caprice Stanley, Tobias Windisch\\nSummary: Graphs on lattice points are studied whose edges come from a finite set of\\nallowed moves of arbitrary length. We show that the diameter of these graphs on\\nfibers of a fixed integer matrix can be bounded from above by a constant. We\\nthen study the mixing behaviour of heat-bath random walks on these graphs. We\\nalso state explicit conditions on the set of moves so that the heat-bath random\\nwalk, a generalization of the Glauber dynamics, is an expander in fixed\\ndimension.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create arxiv tool\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "\n",
    "arxiv = ArxivAPIWrapper()\n",
    "docs = arxiv.run(\"1605.08386\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087a1a3-899a-43cd-b7d7-c5fcaba4d335",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c9861a-047f-4afa-a6a8-2fb53f260e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'alexnet'}`\n",
      "\n",
      "\n",
      "\u001b[33;1m\u001b[1;3mPublished: 2024-04-11\n",
      "Title: Global versus Local: Evaluating AlexNet Architectures for Tropical Cyclone Intensity Estimation\n",
      "Authors: Vikas Dwivedi\n",
      "Summary: Given the destructive impacts of tropical cyclones, it is critical to have a\n",
      "reliable system for cyclone intensity detection. Various techniques are\n",
      "available for this purpose, each with differing levels of accuracy. In this\n",
      "paper, we introduce two ensemble-based models based on AlexNet architecture to\n",
      "estimate tropical cyclone intensity using visible satellite images. The first\n",
      "model, trained on the entire dataset, is called the global AlexNet model. The\n",
      "second model is a distributed version of AlexNet in which multiple AlexNets are\n",
      "trained separately on subsets of the training data categorized according to the\n",
      "Saffir-Simpson wind speed scale prescribed by the meterologists. We evaluated\n",
      "the performance of both models against a deep learning benchmark model called\n",
      "\\textit{Deepti} using a publicly available cyclone image dataset. Results\n",
      "indicate that both the global model (with a root mean square error (RMSE) of\n",
      "9.03 knots) and the distributed model (with a RMSE of 9.3 knots) outperform the\n",
      "benchmark model (with a RMSE of 13.62 knots). We provide a thorough discussion\n",
      "of our solution approach, including an explanantion of the AlexNet's\n",
      "performance using gradient class activation maps (grad-CAM). Our proposed\n",
      "solution strategy allows future experimentation with various deep learning\n",
      "models in both single and multi-channel settings.\n",
      "\n",
      "Published: 2017-01-22\n",
      "Title: Improved Deep Learning of Object Category using Pose Information\n",
      "Authors: Jiaping Zhao, Laurent Itti\n",
      "Summary: Despite significant recent progress, the best available computer vision\n",
      "algorithms still lag far behind human capabilities, even for recognizing\n",
      "individual discrete objects under various poses, illuminations, and\n",
      "backgrounds. Here we present a new approach to using object pose information to\n",
      "improve deep network learning. While existing large-scale datasets, e.g.\n",
      "ImageNet, do not have pose information, we leverage the newly published\n",
      "turntable dataset, iLab-20M, which has ~22M images of 704 object instances shot\n",
      "under different lightings, camera viewpoints and turntable rotations, to do\n",
      "more controlled object recognition experiments. We introduce a new\n",
      "convolutional neural network architecture, what/where CNN (2W-CNN), built on a\n",
      "linear-chain feedforward CNN (e.g., AlexNet), augmented by hierarchical layers\n",
      "regularized by object poses. Pose information is only used as feedback signal\n",
      "during training, in addition to category information; during test, the\n",
      "feedforward network only predicts category. To validate the approach, we train\n",
      "both 2W-CNN and AlexNet using a fraction of the dataset, and 2W-CNN achieves 6%\n",
      "performance improvement in category prediction. We show mathematically that\n",
      "2W-CNN has inherent advantages over AlexNet under the stochastic gradient\n",
      "descent (SGD) optimization procedure. Further more, we fine-tune object\n",
      "recognition on ImageNet by using the pretrained 2W-CNN and AlexNet features on\n",
      "iLab-20M, results show that significant improvements have been achieved,\n",
      "compared with training AlexNet from scratch. Moreover, fine-tuning 2W-CNN\n",
      "features performs even better than fine-tuning the pretrained AlexNet features.\n",
      "These results show pretrained features on iLab- 20M generalizes well to natural\n",
      "image datasets, and 2WCNN learns even better features for object recognition\n",
      "than AlexNet.\n",
      "\n",
      "Published: 2019-09-19\n",
      "Title: Transfer Learning using CNN for Handwritten Devanagari Character Recognition\n",
      "Authors: Nagender Aneja, Sandhya Aneja\n",
      "Summary: This paper presents an analysis of pre-trained models to recognize\n",
      "handwritten Devanagari alphabets using transfer learning for Deep Convolution\n",
      "Neural Network (DCNN). This research implements AlexNet, DenseNet, Vgg, and\n",
      "Inception ConvNet as a fixed feature extractor. We implemented 15 epochs for\n",
      "\u001b[32;1m\u001b[1;3mAlexNet is a deep neural network architecture that was introduced in 2012 by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. It was one of the first deep learning models to win the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012.\n",
      "\n",
      "The AlexNet architecture consists of five convolutional layers followed by three fully connected layers. The model uses a technique called dropout to prevent overfitting during training, and it also uses data augmentation techniques such as random cropping and flipping to improve the generalization performance of the model.\n",
      "\n",
      "AlexNet has been widely used in various computer vision tasks, including image classification, object detection, and segmentation. It has also been used as a baseline for many other deep learning models, and its architecture has inspired the development of many other neural network architectures.\n",
      "\n",
      "In addition to its success in image classification tasks, AlexNet has also been applied to other domains such as handwritten character recognition, where it was used to recognize Devanagari alphabets. The results showed that the pre-trained model achieved high accuracy rates in recognizing handwritten characters.\n",
      "\n",
      "Overall, AlexNet is a significant contribution to the field of deep learning and computer vision, and its architecture has had a lasting impact on the development of many other neural network models.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is alexnet?',\n",
       " 'output': 'AlexNet is a deep neural network architecture that was introduced in 2012 by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. It was one of the first deep learning models to win the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012.\\n\\nThe AlexNet architecture consists of five convolutional layers followed by three fully connected layers. The model uses a technique called dropout to prevent overfitting during training, and it also uses data augmentation techniques such as random cropping and flipping to improve the generalization performance of the model.\\n\\nAlexNet has been widely used in various computer vision tasks, including image classification, object detection, and segmentation. It has also been used as a baseline for many other deep learning models, and its architecture has inspired the development of many other neural network architectures.\\n\\nIn addition to its success in image classification tasks, AlexNet has also been applied to other domains such as handwritten character recognition, where it was used to recognize Devanagari alphabets. The results showed that the pre-trained model achieved high accuracy rates in recognizing handwritten characters.\\n\\nOverall, AlexNet is a significant contribution to the field of deep learning and computer vision, and its architecture has had a lasting impact on the development of many other neural network models.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.tools import WikipediaQueryRun, ArxivQueryRun\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_community.utilities import WikipediaAPIWrapper, ArxivAPIWrapper\n",
    "\n",
    "# Create tools\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "arxiv = ArxivQueryRun(api_wrapper=ArxivAPIWrapper())\n",
    "tools = [wikipedia, arxiv]\n",
    "\n",
    "# Initiate an llm\n",
    "llm = ChatOllama(model=\"llama3.1\")\n",
    "\n",
    "# Initialize the prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"system\", \"You are a helpful assistant\"),\n",
    "                (\"placeholder\", \"{chat_history}\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "                (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# create an agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "\n",
    "# Create agent executor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)\n",
    "\n",
    "agent_executor.invoke({\"input\": \"what is alexnet?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f5e791-79fb-4640-a19c-25249b21fc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc1607-72b0-4f8c-a558-d703e6674f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
