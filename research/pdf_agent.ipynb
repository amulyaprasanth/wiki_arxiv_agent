{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f18586-802a-4f8c-84f9-4424cd89752b",
   "metadata": {},
   "source": [
    "# PDF Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e67ea-2465-4e3b-b63c-ffa46d924a41",
   "metadata": {},
   "source": [
    "### Loading the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778ea96e-db14-4bff-957a-fe90df1bc6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "# Import the required data loaders\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load in the PDf\n",
    "name = '../Building Machine Learning Systems with Python - Second Edition.pdf'\n",
    "\n",
    "# Initlialize the loader\n",
    "loader = PyPDFLoader(name)\n",
    "\n",
    "# Load the pdf\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae5b66",
   "metadata": {},
   "source": [
    "## Text Splitter and WebStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae3c621-b035-4a96-8179-bc36a192f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a text splitter and vector store to store the loaded pdf documents\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Create a text splitter and vector store and split the documents and store it in the vectorstore\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200)\n",
    "doc_splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits, embedding=OllamaEmbeddings(model=\"llama3.1\"))\n",
    "\n",
    "# Create a retriever from vectorstore\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c676a8-70b9-4608-b5c4-049b6cb93150",
   "metadata": {},
   "source": [
    "### Create the RAG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bdbeeb9-660b-42a7-aaba-d749ad250231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book appears to be about machine learning using Python, covering topics such as designing features, writing custom features, and implementing algorithms for classification tasks. It uses examples from image classification and text analysis to illustrate concepts.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1\", temperature=0.5)\n",
    "qa_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, qa_chain)\n",
    "\n",
    "results = rag_chain.invoke(\n",
    "    {\"input\": \"What is the book about?\"})\n",
    "print(results['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71df1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
